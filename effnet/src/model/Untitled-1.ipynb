{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "from src.make_data import effnet_data\n",
    "import utils\n",
    "from src.model import custom_metric\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "# SET CONFIG Effnet\n",
    "\n",
    "cfg = utils.load_yaml(Path(\"../../config/config.yaml\"))\n",
    "#DATA PATH\n",
    "RSNA_2022_PATH = cfg[\"data\"][\"RSNA_2022_PATH\"]\n",
    "TRAIN_IMAGES_PATH = f'{RSNA_2022_PATH}/train_images'\n",
    "TEST_IMAGES_PATH = f'{RSNA_2022_PATH}/test_images'\n",
    "EFFNET_CHECKPOINTS_PATH = cfg[\"data\"][\"EFFNET_CHECKPOINTS_PATH\"]\n",
    "METADATA_PATH = cfg[\"data\"][\"METADATA_PATH\"]\n",
    "\n",
    "#PARAMETER OF EFFNET\n",
    "EFFNET_MAX_TRAIN_BATCHES = int(cfg[\"model\"][\"EFFNET_MAX_TRAIN_BATCHES\"])\n",
    "EFFNET_MAX_EVAL_BATCHES = int(cfg[\"model\"][\"EFFNET_MAX_EVAL_BATCHES\"])\n",
    "ONE_CYCLE_MAX_LR = float(cfg[\"model\"][\"ONE_CYCLE_MAX_LR\"])\n",
    "ONE_CYCLE_PCT_START = float(cfg[\"model\"][\"ONE_CYCLE_PCT_START\"])\n",
    "SAVE_CHECKPOINT_EVERY_STEP = int(cfg[\"model\"][\"SAVE_CHECKPOINT_EVERY_STEP\"])\n",
    "FRAC_LOSS_WEIGHT = float(cfg[\"model\"][\"FRAC_LOSS_WEIGHT\"])\n",
    "PREDICT_MAX_BATCHES = float(cfg[\"model\"][\"PREDICT_MAX_BATCHES\"])\n",
    "N_FOLDS = int(cfg[\"model\"][\"N_FOLDS\"])\n",
    "ONE_CYCLE_EPOCH = int(cfg[\"model\"][\"ONE_CYCLE_EPOCH\"])\n",
    "SEED = int(cfg[\"model\"][\"SEED\"])\n",
    "WEIGHTS = tv.models.efficientnet.EfficientNet_V2_S_Weights.DEFAULT\n",
    "\n",
    "# Common\n",
    "PROJECT_NAME = cfg[\"base\"][\"PROJECT_NAME\"]\n",
    "MODEL_NAME = cfg[\"base\"][\"MODEL_NAME\"]\n",
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if DEVICE == 'cuda':\n",
    "    BATCH_SIZE = cfg[\"model\"][\"BATCH_SIZE\"]\n",
    "else:\n",
    "    BATCH_SIZE = 2\n",
    "\n",
    "#Read csv data for slicing\n",
    "df_train = pd.read_csv(f'{RSNA_2022_PATH}/train.csv')\n",
    "df_train_slices = pd.read_csv(f'{METADATA_PATH}/train_segmented.csv')\n",
    "df_test = pd.read_csv(f'{RSNA_2022_PATH}/test.csv')\n",
    "\n",
    "#PreProcess and Effnetdata\n",
    "df_train,df_train_slices,df_test,df_test_slices = effnet_data.preprocess(df_train = df_train,df_train_slices=df_train_slices,df_test=df_test,TEST_IMAGES_PATH=TEST_IMAGES_PATH,N_FOLDS=N_FOLDS)\n",
    "data_path = Path(\"/home/jumpei.uchida/develop/kaggle_1080ti_1_2/rsna-2022-cervical-spine-fracture-detection/fold0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def patient_prediction(df,frac_cols,vert_cols):\n",
    "    c1c7 = np.average(df[frac_cols].values, axis=0, weights=df[vert_cols].values)\n",
    "    pred_patient_overall = 1 - np.prod(1 - c1c7)\n",
    "    return np.concatenate([[pred_patient_overall], c1c7])\n",
    "\n",
    "def evaluate(df_eval_pred,df_train):\n",
    "    target_cols = ['patient_overall'] + [f'C{i}_fracture' for i in range(1, 8)]\n",
    "    frac_cols = [f'C{i}_effnet_frac' for i in range(1, 8)]\n",
    "    vert_cols = [f'C{i}_effnet_vert' for i in range(1, 8)]\n",
    "\n",
    "    df_patient_eval_pred = df_eval_pred.groupby('StudyInstanceUID').apply(lambda df: patient_prediction(df,frac_cols=frac_cols,vert_cols=vert_cols)).to_frame('pred').join(df_eval_pred.groupby('StudyInstanceUID')[target_cols].mean())\n",
    "\n",
    "\n",
    "    fold_data = df_train[[\"StudyInstanceUID\",\"split\"]].drop_duplicates().reset_index(drop = True)\n",
    "    df_patient_eval_pred = df_patient_eval_pred.merge(fold_data,on  = \"StudyInstanceUID\",how = \"left\")\n",
    "    valid_list = []\n",
    "    for fold in range(N_FOLDS):\n",
    "        df_temp  = df_patient_eval_pred.query(\"split == @fold\")\n",
    "        eval_targets = df_temp[target_cols].values\n",
    "        eval_predictions = np.stack(df_temp.pred.values.tolist())\n",
    "        valid_score = custom_metric.weighted_loss(torch.logit(torch.as_tensor(eval_predictions)).to(DEVICE), torch.as_tensor(eval_targets).to(DEVICE))\n",
    "        valid_list.append(valid_score.cpu())\n",
    "        print(f'Valid_CV score Fold_{fold}:', valid_score)\n",
    "    \n",
    "    \n",
    "    print(f'Valid_CV score :',np.mean(np.array(valid_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_depth(images: np.ndarray, depth, depth_range, enable_depth_resized_with_cv2):\n",
    "    assert images.ndim >= 3  # (..., depth, h/w, w/h)\n",
    "\n",
    "    if depth_range is not None:\n",
    "        assert len(depth_range) == 2\n",
    "        start_idx, end_idx = np.quantile(np.arange(images.shape[-3]), depth_range).astype(int)\n",
    "        images = images[..., start_idx:end_idx, :, :]\n",
    "\n",
    "    if depth is None:\n",
    "        return images\n",
    "\n",
    "    #if images.shape[-3] < depth:\n",
    "    #    warnings.warn(\"images.shape[-3] < given depth\", UserWarning)\n",
    "\n",
    "    if enable_depth_resized_with_cv2:\n",
    "        images = images.swapaxes(-3, -2)\n",
    "        *left_shapes, images_height, images_depth, images_width = images.shape\n",
    "        images = images.reshape((-1, images_depth, images_width))\n",
    "        images = np.stack([\n",
    "            cv2.resize(image, (images_width, depth), interpolation=cv2.INTER_AREA)\n",
    "            for image in images\n",
    "        ], axis=0)\n",
    "        images = images.reshape((*left_shapes, images_height, depth, images_width))\n",
    "        images = images.swapaxes(-3, -2)\n",
    "        return images\n",
    "    else:\n",
    "        indices = np.quantile(\n",
    "            np.arange(images.shape[-3]), np.linspace(0, 1, depth)\n",
    "        ).astype(int)\n",
    "        return images[..., indices, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(temp,custom = True):\n",
    "    assert temp.ndim == 4\n",
    "    c_list = []\n",
    "    for c in range(7):\n",
    "        temp_list = []\n",
    "        for c1 in temp[c]:\n",
    "            temp_list.append(np.sum(c1).astype(\"float64\"))\n",
    "        #temp_list /= max(temp_list)\n",
    "        c_list.append(temp_list)\n",
    "    c_array = np.array(c_list)\n",
    "    if custom:\n",
    "        for num_i,sum_num in enumerate(np.sum(c_array,axis = 0)):\n",
    "            if sum_num > 1.0:\n",
    "                c_array[:,num_i] /= sum_num\n",
    "    \n",
    "    return c_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_pred = pd.read_csv(\"/home/jumpei.uchida/develop/kaggle_1080ti_1_2/rsna-2022-cervical-spine-fracture-detection/effnet/src/saved_model/effnet/temp_eval_prediction.csv\")\n",
    "uid_to_slice_map = df_eval_pred.groupby(\"StudyInstanceUID\")[\"Slice\"].max().to_dict()\n",
    "vert_cols = [f'C{i}_effnet_vert' for i in range(1, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_origin(uid,i,flag_df):\n",
    "    vert_cols = [f'C{i}_effnet_vert' for i in range(1, 8)]\n",
    "    slice = uid_to_slice_map[uid]\n",
    "    temp = np.load(data_path / f\"{uid}.npz\",allow_pickle=True)[\"arr_0\"]\n",
    "    temp = resize_depth(temp,depth = slice,depth_range = None,enable_depth_resized_with_cv2=True)\n",
    "    temp = transforms(temp)\n",
    "    temp = np.nan_to_num(temp)\n",
    "    temp = pd.DataFrame(temp.T,columns = vert_cols)\n",
    "    temp[\"StudyInstanceUID\"] = uid\n",
    "    if flag_df.query(\"StudyInstanceUID == @uid\")[\"Flag\"].values[0] == 0:\n",
    "        temp[\"Slice\"] = [i for i in range(1,slice+1)]\n",
    "    else:\n",
    "        temp[\"Slice\"] = list(reversed([i for i in range(1,slice+1)]))\n",
    "    return temp,i\n",
    "\n",
    "def get_dicom_paths(dicom_dir_path: Path):\n",
    "    dicom_paths = sorted(\n",
    "        dicom_dir_path.glob(\"*\"),\n",
    "        key=lambda p: int(p.name.split(\".\")[0])\n",
    "    )\n",
    "    if (\n",
    "        dicom.dcmread(dicom_paths[0]).get(\"ImagePositionPatient\")[2]\n",
    "        >\n",
    "        dicom.dcmread(dicom_paths[-1]).get(\"ImagePositionPatient\")[2]\n",
    "    ):\n",
    "        return dicom_paths[::-1]\n",
    "    return dicom_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019it [00:00, 245892.73it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_path_list(path,i):\n",
    "    flag = 1\n",
    "    temp = get_dicom_paths(path)\n",
    "    if temp[0].parts[-1] == \"1.dcm\":\n",
    "        flag =0\n",
    "    uid = temp[0].parts[-2]\n",
    "    return [uid,flag],i\n",
    "\n",
    "\n",
    "paths = Path(\"/home/jumpei.uchida/develop/data/rsna/train_images\")\n",
    "path_list = joblib.Parallel(n_jobs=-1)([\n",
    "    joblib.delayed(make_path_list)(path,i)\n",
    "    for i,path in tqdm(enumerate(list(paths.iterdir())))])\n",
    "path_list.sort(key=lambda x: x[1])\n",
    "path_list = [t[0] for t in path_list]\n",
    "flag_df = pd.DataFrame(path_list,columns = [\"StudyInstanceUID\",\"is_reversed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_df.to_csv(\"reversed_uid\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv(f'{RSNA_2022_PATH}/train.csv')\n",
    "df_train_slices = pd.read_csv(f'{METADATA_PATH}/train_segmented.csv')\n",
    "df_test = pd.read_csv(f'{RSNA_2022_PATH}/test.csv')\n",
    "df_train_box = pd.read_csv(f'{RSNA_2022_PATH}/cropped_2d_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uid_list =list(df_train_box[\"StudyInstanceUID\"].unique())\n",
    "df_train = df_train.query(\"StudyInstanceUID == @uid_list | patient_overall == 0\")[[\"StudyInstanceUID\",\"patient_overall\"]].reset_index(drop = True)\n",
    "df_train_box = df_train_box[[\"StudyInstanceUID\",\"slice_number\",\"is_reversed\"]]\n",
    "list_reversed_uid = df_train_box.query(\"is_reversed == True\")[\"StudyInstanceUID\"].unique()\n",
    "train_uid = list(df_train[\"StudyInstanceUID\"].unique())\n",
    "df_train_temp = df_train_slices[[\"StudyInstanceUID\",\"Slice\"]].query(\"StudyInstanceUID == @train_uid\").merge(df_train,on = \"StudyInstanceUID\",how =\"left\")\n",
    "df_train_box = df_train_box.rename(columns={\"slice_number\":\"new_slice\"})\n",
    "list_df_trains = []\n",
    "for uid in list_reversed_uid:\n",
    "    df_temp = df_train_temp.query(\"StudyInstanceUID == @uid\")\n",
    "    df_temp[\"new_slice\"] = df_temp[\"Slice\"].values[::-1]\n",
    "    list_df_trains.append(df_temp)\n",
    "df_others = df_train_temp.query(\"StudyInstanceUID not in  @list_reversed_uid\")\n",
    "df_others[\"new_slice\"] = df_others[\"Slice\"]\n",
    "list_df_trains.append(df_others)\n",
    "df_train = pd.concat(list_df_trains)\n",
    "df_train = df_train.reindex(columns = ['StudyInstanceUID', 'patient_overall', 'Slice', 'new_slice'])\n",
    "df_train = df_train.drop(\"patient_overall\",axis = 1)\n",
    "df_train_box[\"patient_overall\"] = 1\n",
    "df_train =df_train.merge(df_train_box.drop(\"is_reversed\",axis =1),on =[\"StudyInstanceUID\",\"new_slice\"],how = \"left\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "cv = StratifiedGroupKFold(n_splits=N_FOLDS,random_state=44,shuffle=True)\n",
    "for k, (_, test_idx) in enumerate(cv.split(df_train,y = df_train.patient_overall, groups=df_train.StudyInstanceUID)):\n",
    "    df_train.loc[test_idx, 'split'] = k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Slice</th>\n",
       "      <th>new_slice</th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.11300</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.11300</td>\n",
       "      <td>2</td>\n",
       "      <td>234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.11300</td>\n",
       "      <td>3</td>\n",
       "      <td>233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.11300</td>\n",
       "      <td>4</td>\n",
       "      <td>232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.11300</td>\n",
       "      <td>5</td>\n",
       "      <td>231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468401</th>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468402</th>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>252</td>\n",
       "      <td>252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468403</th>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468404</th>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468405</th>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468406 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 StudyInstanceUID  Slice  new_slice  patient_overall  split\n",
       "0       1.2.826.0.1.3680043.11300      1        235              0.0    2.0\n",
       "1       1.2.826.0.1.3680043.11300      2        234              0.0    2.0\n",
       "2       1.2.826.0.1.3680043.11300      3        233              0.0    2.0\n",
       "3       1.2.826.0.1.3680043.11300      4        232              0.0    2.0\n",
       "4       1.2.826.0.1.3680043.11300      5        231              0.0    2.0\n",
       "...                           ...    ...        ...              ...    ...\n",
       "468401   1.2.826.0.1.3680043.9997    251        251              0.0    1.0\n",
       "468402   1.2.826.0.1.3680043.9997    252        252              0.0    1.0\n",
       "468403   1.2.826.0.1.3680043.9997    253        253              0.0    1.0\n",
       "468404   1.2.826.0.1.3680043.9997    254        254              0.0    1.0\n",
       "468405   1.2.826.0.1.3680043.9997    255        255              0.0    1.0\n",
       "\n",
       "[468406 rows x 5 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018it [00:00, 142524.55it/s]\n"
     ]
    }
   ],
   "source": [
    "images = joblib.Parallel(n_jobs=-1)([\n",
    "    joblib.delayed(resize_origin)(uid,i,flag_df)\n",
    "    for i,uid in tqdm(enumerate(list(uid_to_slice_map.keys())))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.sort(key=lambda x: x[1])\n",
    "images = [t[0] for t in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_pred = pd.concat(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred[vert_cols] += 0.000000000000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Slice</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>SliceThickness</th>\n",
       "      <th>ImagePositionPatient_x</th>\n",
       "      <th>ImagePositionPatient_y</th>\n",
       "      <th>ImagePositionPatient_z</th>\n",
       "      <th>C1</th>\n",
       "      <th>...</th>\n",
       "      <th>C5_effnet_frac</th>\n",
       "      <th>C6_effnet_frac</th>\n",
       "      <th>C7_effnet_frac</th>\n",
       "      <th>C1_effnet_vert</th>\n",
       "      <th>C2_effnet_vert</th>\n",
       "      <th>C3_effnet_vert</th>\n",
       "      <th>C4_effnet_vert</th>\n",
       "      <th>C5_effnet_vert</th>\n",
       "      <th>C6_effnet_vert</th>\n",
       "      <th>C7_effnet_vert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.2.826.0.1.3680043.10058</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-53.53546</td>\n",
       "      <td>-69.16046</td>\n",
       "      <td>1839.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.2.826.0.1.3680043.10058</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-53.53546</td>\n",
       "      <td>-69.16046</td>\n",
       "      <td>1839.1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.2.826.0.1.3680043.10058</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-53.53546</td>\n",
       "      <td>-69.16046</td>\n",
       "      <td>1838.7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.2.826.0.1.3680043.10058</td>\n",
       "      <td>4</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-53.53546</td>\n",
       "      <td>-69.16046</td>\n",
       "      <td>1838.3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.2.826.0.1.3680043.10058</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-53.53546</td>\n",
       "      <td>-69.16046</td>\n",
       "      <td>1837.9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           StudyInstanceUID  Slice  ImageHeight  ImageWidth  \\\n",
       "0           0  1.2.826.0.1.3680043.10058      1          512         512   \n",
       "1           1  1.2.826.0.1.3680043.10058      2          512         512   \n",
       "2           2  1.2.826.0.1.3680043.10058      3          512         512   \n",
       "3           3  1.2.826.0.1.3680043.10058      4          512         512   \n",
       "4           4  1.2.826.0.1.3680043.10058      5          512         512   \n",
       "\n",
       "   SliceThickness  ImagePositionPatient_x  ImagePositionPatient_y  \\\n",
       "0             0.5               -53.53546               -69.16046   \n",
       "1             0.5               -53.53546               -69.16046   \n",
       "2             0.5               -53.53546               -69.16046   \n",
       "3             0.5               -53.53546               -69.16046   \n",
       "4             0.5               -53.53546               -69.16046   \n",
       "\n",
       "   ImagePositionPatient_z  C1  ...  C5_effnet_frac  C6_effnet_frac  \\\n",
       "0                  1839.5   0  ...        0.000559        0.000449   \n",
       "1                  1839.1   0  ...        0.000568        0.000478   \n",
       "2                  1838.7   0  ...        0.000526        0.000458   \n",
       "3                  1838.3   0  ...        0.000636        0.000475   \n",
       "4                  1837.9   0  ...        0.000544        0.000341   \n",
       "\n",
       "   C7_effnet_frac  C1_effnet_vert  C2_effnet_vert  C3_effnet_vert  \\\n",
       "0        0.000680        0.000223        0.000303        0.000830   \n",
       "1        0.000801        0.000267        0.000473        0.001174   \n",
       "2        0.000758        0.000238        0.000494        0.001289   \n",
       "3        0.000758        0.000282        0.000441        0.001143   \n",
       "4        0.000467        0.000241        0.000566        0.001501   \n",
       "\n",
       "   C4_effnet_vert  C5_effnet_vert  C6_effnet_vert  C7_effnet_vert  \n",
       "0        0.000782        0.000747        0.000499        0.000462  \n",
       "1        0.000798        0.000661        0.000540        0.000631  \n",
       "2        0.000801        0.000575        0.000499        0.000612  \n",
       "3        0.001279        0.000894        0.000511        0.000547  \n",
       "4        0.001707        0.000940        0.000341        0.000282  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eval_pred = df_eval_pred.drop(vert_cols,axis = 1)\n",
    "df_eval_pred = df_eval_pred.merge(df_pred,on = [\"StudyInstanceUID\",\"Slice\"],how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid_CV score Fold_0: tensor(0.5155, device='cuda:0', dtype=torch.float64)\n",
      "Valid_CV score Fold_1: tensor(0.4857, device='cuda:0', dtype=torch.float64)\n",
      "Valid_CV score Fold_2: tensor(0.4917, device='cuda:0', dtype=torch.float64)\n",
      "Valid_CV score : 0.4976275242739086\n"
     ]
    }
   ],
   "source": [
    "evaluate(df_eval_pred,df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1_effnet_vert</th>\n",
       "      <th>C2_effnet_vert</th>\n",
       "      <th>C3_effnet_vert</th>\n",
       "      <th>C4_effnet_vert</th>\n",
       "      <th>C5_effnet_vert</th>\n",
       "      <th>C6_effnet_vert</th>\n",
       "      <th>C7_effnet_vert</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Slice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C1_effnet_vert  C2_effnet_vert  C3_effnet_vert  C4_effnet_vert  \\\n",
       "0    1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "1    1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "2    1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "3    1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "4    1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "\n",
       "   C5_effnet_vert  C6_effnet_vert  C7_effnet_vert           StudyInstanceUID  \\\n",
       "0    1.000000e-18    1.000000e-18    1.000000e-18  1.2.826.0.1.3680043.10001   \n",
       "1    1.000000e-18    1.000000e-18    1.000000e-18  1.2.826.0.1.3680043.10001   \n",
       "2    1.000000e-18    1.000000e-18    1.000000e-18  1.2.826.0.1.3680043.10001   \n",
       "3    1.000000e-18    1.000000e-18    1.000000e-18  1.2.826.0.1.3680043.10001   \n",
       "4    1.000000e-18    1.000000e-18    1.000000e-18  1.2.826.0.1.3680043.10001   \n",
       "\n",
       "   Slice  \n",
       "0    268  \n",
       "1    267  \n",
       "2    266  \n",
       "3    265  \n",
       "4    264  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rsna-2022-cervical-spine-fracture-detectio--CY1vaQI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9543f5d01a1500c6a5cd37c6db0f31fe3955bfe154c36c5ae281c10861deee7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
