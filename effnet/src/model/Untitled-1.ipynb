{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "from src.make_data import effnet_data\n",
    "import utils\n",
    "from src.model import custom_metric\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "# SET CONFIG Effnet\n",
    "\n",
    "cfg = utils.load_yaml(Path(\"../../config/config.yaml\"))\n",
    "#DATA PATH\n",
    "RSNA_2022_PATH = cfg[\"data\"][\"RSNA_2022_PATH\"]\n",
    "TRAIN_IMAGES_PATH = f'{RSNA_2022_PATH}/train_images'\n",
    "TEST_IMAGES_PATH = f'{RSNA_2022_PATH}/test_images'\n",
    "EFFNET_CHECKPOINTS_PATH = cfg[\"data\"][\"EFFNET_CHECKPOINTS_PATH\"]\n",
    "METADATA_PATH = cfg[\"data\"][\"METADATA_PATH\"]\n",
    "\n",
    "#PARAMETER OF EFFNET\n",
    "EFFNET_MAX_TRAIN_BATCHES = int(cfg[\"model\"][\"EFFNET_MAX_TRAIN_BATCHES\"])\n",
    "EFFNET_MAX_EVAL_BATCHES = int(cfg[\"model\"][\"EFFNET_MAX_EVAL_BATCHES\"])\n",
    "ONE_CYCLE_MAX_LR = float(cfg[\"model\"][\"ONE_CYCLE_MAX_LR\"])\n",
    "ONE_CYCLE_PCT_START = float(cfg[\"model\"][\"ONE_CYCLE_PCT_START\"])\n",
    "SAVE_CHECKPOINT_EVERY_STEP = int(cfg[\"model\"][\"SAVE_CHECKPOINT_EVERY_STEP\"])\n",
    "FRAC_LOSS_WEIGHT = float(cfg[\"model\"][\"FRAC_LOSS_WEIGHT\"])\n",
    "PREDICT_MAX_BATCHES = float(cfg[\"model\"][\"PREDICT_MAX_BATCHES\"])\n",
    "N_FOLDS = int(cfg[\"model\"][\"N_FOLDS\"])\n",
    "ONE_CYCLE_EPOCH = int(cfg[\"model\"][\"ONE_CYCLE_EPOCH\"])\n",
    "SEED = int(cfg[\"model\"][\"SEED\"])\n",
    "WEIGHTS = tv.models.efficientnet.EfficientNet_V2_S_Weights.DEFAULT\n",
    "\n",
    "# Common\n",
    "PROJECT_NAME = cfg[\"base\"][\"PROJECT_NAME\"]\n",
    "MODEL_NAME = cfg[\"base\"][\"MODEL_NAME\"]\n",
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if DEVICE == 'cuda':\n",
    "    BATCH_SIZE = cfg[\"model\"][\"BATCH_SIZE\"]\n",
    "else:\n",
    "    BATCH_SIZE = 2\n",
    "\n",
    "#Read csv data for slicing\n",
    "df_train = pd.read_csv(f'{RSNA_2022_PATH}/train.csv')\n",
    "df_train_slices = pd.read_csv(f'{METADATA_PATH}/train_segmented.csv')\n",
    "df_test = pd.read_csv(f'{RSNA_2022_PATH}/test.csv')\n",
    "\n",
    "#PreProcess and Effnetdata\n",
    "df_train,df_train_slices,df_test,df_test_slices = effnet_data.preprocess(df_train = df_train,df_train_slices=df_train_slices,df_test=df_test,TEST_IMAGES_PATH=TEST_IMAGES_PATH,N_FOLDS=N_FOLDS)\n",
    "data_path = Path(\"/home/jumpei.uchida/develop/kaggle_1080ti_1_2/rsna-2022-cervical-spine-fracture-detection/fold0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def patient_prediction(df,frac_cols,vert_cols):\n",
    "    c1c7 = np.average(df[frac_cols].values, axis=0, weights=df[vert_cols].values)\n",
    "    pred_patient_overall = 1 - np.prod(1 - c1c7)\n",
    "    return np.concatenate([[pred_patient_overall], c1c7])\n",
    "\n",
    "def evaluate(df_eval_pred,df_train):\n",
    "    target_cols = ['patient_overall'] + [f'C{i}_fracture' for i in range(1, 8)]\n",
    "    frac_cols = [f'C{i}_effnet_frac' for i in range(1, 8)]\n",
    "    vert_cols = [f'C{i}_effnet_vert' for i in range(1, 8)]\n",
    "\n",
    "    df_patient_eval_pred = df_eval_pred.groupby('StudyInstanceUID').apply(lambda df: patient_prediction(df,frac_cols=frac_cols,vert_cols=vert_cols)).to_frame('pred').join(df_eval_pred.groupby('StudyInstanceUID')[target_cols].max())\n",
    "\n",
    "\n",
    "    fold_data = df_train[[\"StudyInstanceUID\",\"split\"]].drop_duplicates().reset_index(drop = True)\n",
    "    df_patient_eval_pred = df_patient_eval_pred.merge(fold_data,on  = \"StudyInstanceUID\",how = \"left\")\n",
    "    valid_list = []\n",
    "    for fold in range(N_FOLDS):\n",
    "        df_temp  = df_patient_eval_pred.query(\"split == @fold\")\n",
    "        eval_targets = df_temp[target_cols].values\n",
    "        eval_predictions = np.stack(df_temp.pred.values.tolist())\n",
    "        valid_score = custom_metric.weighted_loss(torch.logit(torch.as_tensor(eval_predictions)).to(DEVICE).to(torch.float), torch.as_tensor(eval_targets).to(DEVICE).to(torch.float))\n",
    "        valid_list.append(valid_score.cpu())\n",
    "        print(f'Valid_CV score Fold_{fold}:', valid_score)\n",
    "    \n",
    "    \n",
    "    print(f'Valid_CV score :',np.mean(np.array(valid_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_depth(images: np.ndarray, depth, depth_range, enable_depth_resized_with_cv2):\n",
    "    assert images.ndim >= 3  # (..., depth, h/w, w/h)\n",
    "\n",
    "    if depth_range is not None:\n",
    "        assert len(depth_range) == 2\n",
    "        start_idx, end_idx = np.quantile(np.arange(images.shape[-3]), depth_range).astype(int)\n",
    "        images = images[..., start_idx:end_idx, :, :]\n",
    "\n",
    "    if depth is None:\n",
    "        return images\n",
    "\n",
    "    #if images.shape[-3] < depth:\n",
    "    #    warnings.warn(\"images.shape[-3] < given depth\", UserWarning)\n",
    "\n",
    "    if enable_depth_resized_with_cv2:\n",
    "        images = images.swapaxes(-3, -2)\n",
    "        *left_shapes, images_height, images_depth, images_width = images.shape\n",
    "        images = images.reshape((-1, images_depth, images_width))\n",
    "        images = np.stack([\n",
    "            cv2.resize(image, (images_width, depth), interpolation=cv2.INTER_AREA)\n",
    "            for image in images\n",
    "        ], axis=0)\n",
    "        images = images.reshape((*left_shapes, images_height, depth, images_width))\n",
    "        images = images.swapaxes(-3, -2)\n",
    "        return images\n",
    "    else:\n",
    "        indices = np.quantile(\n",
    "            np.arange(images.shape[-3]), np.linspace(0, 1, depth)\n",
    "        ).astype(int)\n",
    "        return images[..., indices, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforms(temp,custom = True):\n",
    "    assert temp.ndim == 4\n",
    "    c_list = []\n",
    "    for c in range(7):\n",
    "        temp_list = []\n",
    "        for c1 in temp[c]:\n",
    "            temp_list.append(np.sum(c1).astype(\"float64\"))\n",
    "        temp_list /= max(temp_list)\n",
    "        c_list.append(temp_list)\n",
    "    c_array = np.array(c_list)\n",
    "    if custom:\n",
    "        for num_i,sum_num in enumerate(np.sum(c_array,axis = 0)):\n",
    "            if sum_num > 1.0:\n",
    "                c_array[:,num_i] /= sum_num\n",
    "    \n",
    "    return c_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_pred = pd.read_csv(\"/home/jumpei.uchida/develop/kaggle_1080ti_1_2/rsna-2022-cervical-spine-fracture-detection/effnet/src/saved_model/effnet/temp_eval_prediction.csv\")\n",
    "uid_to_slice_map = df_eval_pred.groupby(\"StudyInstanceUID\")[\"Slice\"].max().to_dict()\n",
    "vert_cols = [f'C{i}_effnet_vert' for i in range(1, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_origin(uid,i,flag_df):\n",
    "    vert_cols = [f'C{i}_effnet_vert' for i in range(1, 8)]\n",
    "    slice = uid_to_slice_map[uid]\n",
    "    temp = np.load(data_path / f\"{uid}.npz\",allow_pickle=True)[\"arr_0\"]\n",
    "    temp = resize_depth(temp,depth = slice,depth_range = None,enable_depth_resized_with_cv2=True)\n",
    "    temp = transforms(temp)\n",
    "    temp = np.nan_to_num(temp)\n",
    "    temp = pd.DataFrame(temp.T,columns = vert_cols)\n",
    "    temp[\"StudyInstanceUID\"] = uid\n",
    "    if flag_df.query(\"StudyInstanceUID == @uid\")[\"is_reversed\"].values[0] == 0:\n",
    "        temp[\"Slice\"] = [i for i in range(1,slice+1)]\n",
    "    else:\n",
    "        temp[\"Slice\"] = list(reversed([i for i in range(1,slice+1)]))\n",
    "    return temp,i\n",
    "\n",
    "def get_dicom_paths(dicom_dir_path: Path):\n",
    "    dicom_paths = sorted(\n",
    "        dicom_dir_path.glob(\"*\"),\n",
    "        key=lambda p: int(p.name.split(\".\")[0])\n",
    "    )\n",
    "    if (\n",
    "        dicom.dcmread(dicom_paths[0]).get(\"ImagePositionPatient\")[2]\n",
    "        >\n",
    "        dicom.dcmread(dicom_paths[-1]).get(\"ImagePositionPatient\")[2]\n",
    "    ):\n",
    "        return dicom_paths[::-1]\n",
    "    return dicom_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019it [00:00, 225676.89it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_path_list(path,i):\n",
    "    flag = 1\n",
    "    temp = get_dicom_paths(path)\n",
    "    if temp[0].parts[-1] == \"1.dcm\":\n",
    "        flag =0\n",
    "    uid = temp[0].parts[-2]\n",
    "    return [uid,flag],i\n",
    "\n",
    "\n",
    "paths = Path(\"/home/jumpei.uchida/develop/data/rsna/train_images\")\n",
    "path_list = joblib.Parallel(n_jobs=-1)([\n",
    "    joblib.delayed(make_path_list)(path,i)\n",
    "    for i,path in tqdm(enumerate(list(paths.iterdir())))])\n",
    "path_list.sort(key=lambda x: x[1])\n",
    "path_list = [t[0] for t in path_list]\n",
    "flag_df = pd.DataFrame(path_list,columns = [\"StudyInstanceUID\",\"is_reversed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018it [00:00, 119581.60it/s]\n"
     ]
    }
   ],
   "source": [
    "images = joblib.Parallel(n_jobs=-1)([\n",
    "    joblib.delayed(resize_origin)(uid,i,flag_df)\n",
    "    for i,uid in tqdm(enumerate(list(uid_to_slice_map.keys())))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.sort(key=lambda x: x[1])\n",
    "images = [t[0] for t in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_pred = pd.concat(images)\n",
    "df_pred[vert_cols] += 0.000000000000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1_effnet_vert</th>\n",
       "      <th>C2_effnet_vert</th>\n",
       "      <th>C3_effnet_vert</th>\n",
       "      <th>C4_effnet_vert</th>\n",
       "      <th>C5_effnet_vert</th>\n",
       "      <th>C6_effnet_vert</th>\n",
       "      <th>C7_effnet_vert</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Slice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.000000e-18</td>\n",
       "      <td>1.2.826.0.1.3680043.9997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>711570 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     C1_effnet_vert  C2_effnet_vert  C3_effnet_vert  C4_effnet_vert  \\\n",
       "0      1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "1      1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "2      1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "3      1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "4      1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "..              ...             ...             ...             ...   \n",
       "250    1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "251    1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "252    1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "253    1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "254    1.000000e-18    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "\n",
       "     C5_effnet_vert  C6_effnet_vert  C7_effnet_vert  \\\n",
       "0      1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "1      1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "2      1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "3      1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "4      1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "..              ...             ...             ...   \n",
       "250    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "251    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "252    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "253    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "254    1.000000e-18    1.000000e-18    1.000000e-18   \n",
       "\n",
       "              StudyInstanceUID  Slice  \n",
       "0    1.2.826.0.1.3680043.10001    268  \n",
       "1    1.2.826.0.1.3680043.10001    267  \n",
       "2    1.2.826.0.1.3680043.10001    266  \n",
       "3    1.2.826.0.1.3680043.10001    265  \n",
       "4    1.2.826.0.1.3680043.10001    264  \n",
       "..                         ...    ...  \n",
       "250   1.2.826.0.1.3680043.9997      5  \n",
       "251   1.2.826.0.1.3680043.9997      4  \n",
       "252   1.2.826.0.1.3680043.9997      3  \n",
       "253   1.2.826.0.1.3680043.9997      2  \n",
       "254   1.2.826.0.1.3680043.9997      1  \n",
       "\n",
       "[711570 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eval_pred = df_eval_pred.drop(vert_cols,axis = 1)\n",
    "df_eval_pred = df_eval_pred.merge(df_pred,on = [\"StudyInstanceUID\",\"Slice\"],how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid_CV score Fold_0: tensor(0.5155, device='cuda:0')\n",
      "Valid_CV score Fold_1: tensor(0.4857, device='cuda:0')\n",
      "Valid_CV score Fold_2: tensor(0.4917, device='cuda:0')\n",
      "Valid_CV score : 0.4976275\n"
     ]
    }
   ],
   "source": [
    "evaluate(df_eval_pred,df_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('rsna-2022-cervical-spine-fracture-detectio--CY1vaQI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9543f5d01a1500c6a5cd37c6db0f31fe3955bfe154c36c5ae281c10861deee7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
